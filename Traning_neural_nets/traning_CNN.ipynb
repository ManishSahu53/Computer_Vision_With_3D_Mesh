{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.contrib.layers import flatten\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"../data_set/test_images4/anim0.png\")\n",
    "img = cv2.resize(img,(96,96))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "images=[]\n",
    "for i in range(10000):\n",
    "    file_name = \"../data_set/test_images4/anim{}.png\".format(i)\n",
    "    img = cv2.imread(file_name)\n",
    "    img_resize = cv2.resize(img,(96,96))\n",
    "    images.append(img_resize)\n",
    "for i in range(10000):\n",
    "    file_name = \"../data_set/test_images5/anim{}.png\".format(i)\n",
    "    img = cv2.imread(file_name)\n",
    "    img_resize = cv2.resize(img,(96,96))\n",
    "    images.append(img_resize)\n",
    "for i in range(20000):\n",
    "    file_name = \"../data_set/test_images6/anim{}.png\".format(i)\n",
    "    img = cv2.imread(file_name)\n",
    "    img_resize = cv2.resize(img,(96,96))\n",
    "    images.append(img_resize)\n",
    "for i in range(20000):\n",
    "    file_name = \"../data_set/test_images7/anim{}.png\".format(i)\n",
    "    img = cv2.imread(file_name)\n",
    "    img_resize = cv2.resize(img,(96,96))\n",
    "    images.append(img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json1_file = open('../data_set/test_images4/camera_pose.json')\n",
    "json1_str = json1_file.read()\n",
    "json1_data = json.loads(json1_str)\n",
    "\n",
    "json2_file = open('../data_set/test_images5/camera_pose.json')\n",
    "json2_str = json2_file.read()\n",
    "json2_data = json.loads(json2_str)\n",
    "\n",
    "json3_file = open('../data_set/test_images6/camera_pose.json')\n",
    "json3_str = json3_file.read()\n",
    "json3_data = json.loads(json3_str)\n",
    "\n",
    "json4_file = open('../data_set/test_images7/camera_pose.json')\n",
    "json4_str = json4_file.read()\n",
    "json4_data = json.loads(json4_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#json1_data['camera_poses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(10000):\n",
    "    pose_name = \"anim{}_camera_pos\".format(i)\n",
    "    pose = json1_data['camera_poses'][pose_name]\n",
    "    labels.append(pose)\n",
    "for i in range(10000):\n",
    "    pose_name = \"anim{}_camera_pos\".format(i)\n",
    "    pose = json2_data['camera_poses'][pose_name]\n",
    "    labels.append(pose)\n",
    "for i in range(20000):\n",
    "    pose_name = \"anim{}_camera_pos\".format(i)\n",
    "    pose = json3_data['camera_poses'][pose_name]\n",
    "    labels.append(pose)\n",
    "for i in range(20000):\n",
    "    pose_name = \"anim{}_camera_pos\".format(i)\n",
    "    pose = json4_data['camera_poses'][pose_name]\n",
    "    labels.append(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train=shuffle(images,labels)\n",
    "#X_train = tf.image.resize_images(X_train1,[96,96],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_u=0\n",
    "sigma=0.1\n",
    "learning_rate = 0.001\n",
    "batch_size = 1000\n",
    "training_epochs = 30\n",
    "dropout=0.80\n",
    "\n",
    "#save_file = 'model_new.ckpt'\n",
    "from tensorflow.contrib.layers import flatten\n",
    "def NeuralNet(x):    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    # Layer 1: Convolutional. Input = 96x96x3. Output = 92x92x28x6.\n",
    "    newconv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "    newconv1_b = tf.Variable(tf.zeros(6))\n",
    "    newconv1   = tf.nn.conv2d(x, newconv1_W, strides=[1, 1, 1, 1], padding='VALID') + newconv1_b\n",
    "\n",
    "    # Activation.\n",
    "    newconv1 = tf.nn.relu(newconv1)\n",
    "    # Input = 92x92x6. Output = 80x80x12.\n",
    "    newconv2_W=tf.Variable(tf.truncated_normal(shape=(13,13,6,12),mean=mu,stddev=sigma))\n",
    "    newconv2_b=tf.Variable(tf.zeros(12))\n",
    "    newconv2=tf.nn.conv2d(newconv1,newconv2_W,strides=[1,1,1,1],padding='VALID')+newconv2_b    \n",
    "    # Pooling. Input = 80x80x12. Output = 40x40x12.\n",
    "    newconv2 = tf.nn.max_pool(newconv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # layer 2 : input 40x40x12, and output 36x36x16\n",
    "    newconv3_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 12, 16), mean = mu, stddev = sigma))\n",
    "    newconv3_b = tf.Variable(tf.zeros(16))\n",
    "    newconv3   = tf.nn.conv2d(newconv2, newconv3_W, strides=[1, 1, 1, 1], padding='VALID') + newconv3_b\n",
    "    \n",
    "    newconv3 = tf.nn.relu(newconv3)\n",
    "    # Pooling. Input = 36x36x16. Output = 18x18x16.\n",
    "    newconv3 = tf.nn.max_pool(newconv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 4: Convolutional. Output = 14x14x18.\n",
    "    newconv4_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 16, 18), mean = mu, stddev = sigma))\n",
    "    newconv4_b = tf.Variable(tf.zeros(18))\n",
    "    newconv4   = tf.nn.conv2d(newconv3, newconv4_W, strides=[1, 1, 1, 1], padding='VALID') + newconv4_b\n",
    "    \n",
    "    # Activation.\n",
    "    newconv4 = tf.nn.relu(newconv4)\n",
    "\n",
    "    # Pooling. Input = 14x14x18. Output = 7x7x18.\n",
    "    newconv4 = tf.nn.max_pool(newconv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten. Input = 7x7x18. Output = 882.\n",
    "    newfc0 = flatten(newconv4)\n",
    "    newfc0 = tf.nn.dropout(newfc0,dropout)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 882. Output = 400.\n",
    "    newfc1_W = tf.Variable(tf.truncated_normal(shape=(882, 400), mean = mu, stddev = sigma))\n",
    "    newfc1_b = tf.Variable(tf.zeros(400))\n",
    "    newfc1   = tf.matmul(newfc0, newfc1_W) + newfc1_b\n",
    "    \n",
    "    # Activation.\n",
    "    newfc1    = tf.nn.relu(newfc1)\n",
    "    #add dropout\n",
    "    newfc1=tf.nn.dropout(newfc1,dropout)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 400. Output = 84.\n",
    "    newfc2_W  = tf.Variable(tf.truncated_normal(shape=(400, 84), mean = mu, stddev = sigma))\n",
    "    newfc2_b  = tf.Variable(tf.zeros(84))\n",
    "    newfc2    = tf.matmul(newfc1, newfc2_W) + newfc2_b\n",
    "    \n",
    "    # Activation.\n",
    "    newfc2    = tf.nn.relu(newfc2)\n",
    "    #add dropout \n",
    "    newfc2 = tf.nn.dropout(newfc2, dropout)\n",
    "    \n",
    "    \n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 6.\n",
    "    newfc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 6), mean = mu, stddev = sigma))\n",
    "    newfc3_b  = tf.Variable(tf.zeros(6))\n",
    "    logits = tf.matmul(newfc2, newfc3_W) + newfc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construct functions for the neural nets\n",
    "x=tf.placeholder(tf.float32,(None,96,96,3))\n",
    "y=tf.placeholder(tf.float32,(None,6))\n",
    "# one_hot_y=tf.one_hot(y,8)\n",
    "# logits=NeuralNet(x)\n",
    "# cross_entropy=tf.nn.softmax_cross_entropy_with_logits(labels = one_hot_y,logits = logits)\n",
    "# loss_operation=tf.reduce_mean(cross_entropy)\n",
    "predictions = NeuralNet(x)\n",
    "#error = tf.reduce_mean(tf.square(y - predictions))\n",
    "error = tf.reduce_mean(tf.losses.absolute_difference(labels = y,predictions = predictions)) \n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "#training_operation=optimizer.minimize(loss_operation)\n",
    "training_operation = optimizer.minimize(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross_prediction=tf.equal(tf.argmax(logits,1),tf.argmax(one_hot_y,1))\n",
    "#accuracy_operation=tf.reduce_mean(tf.cast(cross_prediction,tf.float32))\n",
    "#validation_error = tf.reduce_mean(tf.square(y - predictions))\n",
    "validation_error = tf.reduce_mean(tf.losses.absolute_difference(labels = y,predictions = predictions)) \n",
    "def evaluation(X_data,y_data):\n",
    "    num_examples=len(X_data)\n",
    "    total_accuracy=0\n",
    "    sess=tf.get_default_session()\n",
    "    for offset in range(0,num_examples,batch_size):\n",
    "        batch_x,batch_y=X_data[offset:offset+batch_size],y_data[offset:offset+batch_size]\n",
    "        accuracy=sess.run(validation_error,feed_dict={x:batch_x,y:batch_y})\n",
    "        total_accuracy+=(accuracy*len(batch_x))\n",
    "    return total_accuracy/num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are training our model\n",
      "\n",
      "epoch1:\n",
      "the validation error:50.977\n",
      "\n",
      "epoch2:\n",
      "the validation error:38.601\n",
      "\n",
      "epoch3:\n",
      "the validation error:37.097\n",
      "\n",
      "epoch4:\n",
      "the validation error:34.885\n",
      "\n",
      "epoch5:\n",
      "the validation error:30.944\n",
      "\n",
      "epoch6:\n",
      "the validation error:29.733\n",
      "\n",
      "epoch7:\n",
      "the validation error:28.794\n",
      "\n",
      "epoch8:\n",
      "the validation error:28.491\n",
      "\n",
      "epoch9:\n",
      "the validation error:27.271\n",
      "\n",
      "epoch10:\n",
      "the validation error:27.129\n",
      "\n",
      "epoch11:\n",
      "the validation error:26.401\n",
      "\n",
      "epoch12:\n",
      "the validation error:25.164\n",
      "\n",
      "epoch13:\n",
      "the validation error:24.798\n",
      "\n",
      "epoch14:\n",
      "the validation error:24.774\n",
      "\n",
      "epoch15:\n",
      "the validation error:22.480\n",
      "\n",
      "epoch16:\n",
      "the validation error:23.437\n",
      "\n",
      "epoch17:\n",
      "the validation error:22.964\n",
      "\n",
      "epoch18:\n",
      "the validation error:24.572\n",
      "\n",
      "epoch19:\n",
      "the validation error:23.566\n",
      "\n",
      "epoch20:\n",
      "the validation error:23.787\n",
      "\n",
      "epoch21:\n",
      "the validation error:22.716\n",
      "\n",
      "epoch22:\n",
      "the validation error:22.274\n",
      "\n",
      "epoch23:\n",
      "the validation error:23.563\n",
      "\n",
      "epoch24:\n",
      "the validation error:21.371\n",
      "\n",
      "epoch25:\n",
      "the validation error:18.895\n",
      "\n",
      "epoch26:\n",
      "the validation error:19.905\n",
      "\n",
      "epoch27:\n",
      "the validation error:19.512\n",
      "\n",
      "epoch28:\n",
      "the validation error:19.216\n",
      "\n",
      "epoch29:\n",
      "the validation error:20.158\n",
      "\n",
      "epoch30:\n",
      "the validation error:21.354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_data,validation_data,training_label,validation_label=train_test_split(X_train,y_train,test_size=0.2)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples=len(training_data)\n",
    "    print(\"we are training our model\")\n",
    "    print()\n",
    "    for i in range(training_epochs):\n",
    "        X_train1,y_train1=shuffle(training_data,training_label)\n",
    "        for offset in range(0,num_examples,batch_size):\n",
    "            end=offset+batch_size\n",
    "            batch_x,batch_y=X_train[offset:end],y_train[offset:end]\n",
    "            sess.run(training_operation,feed_dict={x:batch_x,y:batch_y})\n",
    "        v_accuracy=evaluation(validation_data,validation_label)\n",
    "        print(\"epoch{}:\".format(i+1))\n",
    "        print(\"the validation error:{:.3f}\".format(v_accuracy))\n",
    "        print()\n",
    "    #cross=tf.equal(tf.argmax(logits,1),tf.argmax(one_hot_y,1))\n",
    "    #accuracy=tf.reduce_mean(tf.cast(cross_prediction,tf.float32))   \n",
    "    #print(\"the test accuracy after using regularization is:\",accuracy.eval({x:X_test,y:y_test}))\n",
    "    #saver.save(sess, save_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
